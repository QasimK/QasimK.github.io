---
layout: remark-talk
title: Automating Code Review As Much As Possible
where: PyCon UK 2019
date: 2019-09-07
---

<style>
  .remark-slide-content h1 {
    font-size: 53px;
  }
</style>

# Automating Code Review As Much As Possible

.subtitle[
While the best code is no code at all, we do need to deal with the rest of it.
]

### [QasimK.io](https://QasimK.io) @ PyCon UK 2019

```python
# Automation 101*
def test_continuous_integration_pipeline_is_working():
    msg = requests.get('http://whatthecommit.com/index.txt').text
    subprocess.call([
        'git', 'commit', '--all', '--no-verify', '--author=Bot<>', '-m', msg
    ])
    subprocess.call(['git', 'push', '-fu'])

    if input() == 'Does anyone know why master is broken, AGAIN?':
        print('Nope!')
```

.footnote.smaller[.red[*] Side-effects may include irritated colleagues and performance improvement plans.]

???

I've experienced a variety of different ways to review code.

* As the saying goes, the best code is no code at all.
* This naturally means the rest of your codebase, which is about - all of it - is *not* the best code.
* Code review lets us deal with this situation.
* And I believe we have the same principle for code review - the best code reviewing is when *you're* not doing it.
* So naturally, this talk is about how to most effectively be lazy.

---

# Overview

* What is involved in code review, and what can we actually automate?

* What tools are available for Python, and what should we actually use?

* How can these be used, and how should we actually integrate them into our workflows?

???

(1 - We will briefly cover what we trying to gain from code review.)

[SLIDE] 2 & 3

Let's briefly cover what we are actually trying to automate.

---

## What do we gain from Code Review?

* Catch bugs
* Enforce security
* Code that is easier to read, maintain, and extend
* An opportunity to mentor and learn

???

We want to be able to catch bugs, reduce security vulnerabilities, make the code more maintainable, and this as an opportunity to teach and learn.

All of these aspects, save the last, can partially be automated.

--

## What do we gain from automating these things?

* Reduction in the total time everyone spends reviewing code.
* Ability to review your own code before asking someone else.
* Less nitpicking and conflicts of opinion.
* Ability to focus on what matters the most.

???

**GAIN**

[SLIDE] 1

After 1 - It is not a joke that at one point I was spending more time reviewing code than actually coding.

[SLIDE] 2 & 3

4 - Overall, you save time to focus on higher-level concerns that current tooling cannot consider intelligently, such as architectural issues and project-specific knowledge.

--

## What can we lose from automating these things?

* Time spent setting up the tools
* Time spent changing code that does not actually improve things

???

**LOSE**

Some tools require much more set up and careful introduction to the codebase than others, and this by itself can take up a lot of time.

In addition, when a tool is improperly configured it can have excessive output and false positives leading them to be ignored or even hated. This results in time being lost maintaining the tool.

We need to make sure that we use the right tools for the situation, properly configured and strongly integrated within our workflows to gain the benefits on offer.

---

class: center, middle, inverse

# The Right Tools for the Job

???

Let's start off by looking at the tools available for Python.

---

# How can we check code style?

???

At the most basic, and least important level is the formatting of the code.

I think this is important, but it less important than real bugs and security concerns.

I am not going to talk about why consistency of code style is important, but instead jump into how to do it.

As recently as last year I would have talked about tools like pycodestyle, flake8 or pylint that check against PEP8 and then output errors. These tools are literally evil.

Do. Not. Use. Them. To check your code formatting.

They are literally evil because of:

1. The massive back and forth they cause [DESCRIBE]
2. Their configurability [DESCRIBE]

What you want to use is black, isort and docformatter.

---

# How can we check code style?

## black + isort + docformatter

Once upon a time someone implemented the three terrific tools:

* `black` the uncompromising code formatter
* `isort` the compromising import sorter
* `docformatter` the fiddly docstring formatter

Everyone lived happily ever after.

The End.

???

Black formats your code for you. That is, it re-writes your code to fit the standard code style standard that is standard.

One sensible standard for every codebase, every project, no matter where you are or who you are working with. No more adapting when you work on open source projects or change teams. No more nitpicking on pull requests, ever. No more thinking about code formatting, ever.

Black compromises in giving you choice in two areas only. The line length and whether you want to normalise strings to double quotes.

It is great - everyone should use it.

isort formats your imports, and does actually give you some choice over how you want to do it.

docformatter formats your docstrings, but you do have to be careful with it, because, it can mess up your docstrings at first.

Overall, black is a no-brainer, it is fast to implement, it is fast to use, and it comes in peace even if it will nuke your entire codebase at first.

I would also recommend isort, but merely suggest docformatter.

---

# How can we check code style?

## What's left?

* Other files—`.editorconfig`—<https://editorconfig.org/>

  ![](../../2019-09-13-editorconfig.png)

* Spell checking

  ![](../../2019-09-13-spell-checking-ide.png)

???

So what's left?

Well, you have other files in your codebase, and EditorConfig will let you define some basic standards for those files to be automatically applied when you are editing the file. [EXAMPLE].

EditorConfig comes integrated with many IDEs like PyCharm, and is available as a plugin for others like Atom, Sublime Text, VS Code, and Vim.

Spell Checking.

Perfect spelling would be nice, but I don't see actual, mandatory spell checking going down well with any team, if for no other reason other than there would be far too many false positives for it to actually be worthwhile.

I know of no tool that can automatically and accurately fix your spelling for coding purposes.

However, if your IDE supports it, this is quite natural to use to the point where it seems almost strange to say it. If it doesn't - add a spell checker!

---

# How can we catch bugs?

???

Automated tools catch bugs by looking for known code smells, known dangerous code patterns, and code that is known to unintuitively cause unintended results.

Unlike black, unfortunately the tools here are not revolutionary, but they are already quite well known.

Nevertheless, I think some are more useful, easier to use, or faster to implement than others.

--

## Pyflakes / flake8

```py
assert (1 == 2, "1 is not 2, everything is okay!")
```

```sql
$ pyflakes .
./main.py:1: assertion is always true, perhaps remove parentheses?
```

(With `flake8` disable style checking, it's unnecessary with `black`!)

.footnote[`flake8` = `pyflakes` + `pycodestyle` + `mccabe`]

???

**Pyflakes** checks each file individually, making it fast, and aims to never complain about style or give you false positives. This makes it easy to use this tool everywhere.

[TALK ABOUT CONTRIVED EXAMPLE]

This specific example I probably would not have picked up in code review, because it wouldn't have crossed my mind before now!

---

# How can we catch bugs?

## .red[McCabe]

McCabe code complexity measures the number of different paths a function can take.

```python
def way_too_complex_for_my_brain():
    if True:
        print('True')
```

```sql
$ flake8 --max-complexity=1
./main.py:1:1: C901 'way_too_complex_for_my_brain' is too complex (2)
```

???

[SLIDE]

Personally, I don't think McCabe is particularly useful because you can generally tell when something is complicated.

It might be useful to set a large upper limit, but it is too easy to get around this without properly refactoring the code.

So, I think, while interesting, this tool has limited utility.

---

# How can we catch bugs?

## Pylint

* Covers code style, conventions, warnings, errors, unused and duplicated code
* An order of magnitude slower than `pyflakes`
* Far too configurable

???

[SLIDE]

Pylint is far too configurable, usually producing far too many false positives, which is why it's usually further down on my suggestions.

--

## Optional Type Checking (MyPy/Pyre)

* Type annotations are optional, but can be verified

???

**Type hints** in Python are exactly that: optional hints. They are very helpful in improving code completion and to serve as documentation. The bigger the project the more useful they become.

MyPy and Pyre are the two biggest tools to verify the type annotations.

---

# How can we check security?

???

We can certainly make an attempt at it.

[TALK OVER SLIDES]

It can point out security issues that you might not even be aware of.

--

## Bandit

Finding common security mistakes.

--

```py
import lxml
```

--

```console
$ bandit -r .
Issue: [B410:blacklist] Using lxml to parse untrusted XML data is known to be
vulnerable to XML attacks. Replace lxml with the equivalent defusedxml package.
   Severity: Low   Confidence: High
   Location: ./main.py:1
   More Info: bandit.readthedocs.io/en/latest/blacklists/blacklist_imports.html
#b410-import-lxml
1       import lxml
```

---

# How can we check security?

## Bandit

Finding common has-nothing-to-do-with-security-in-this-case.

```py
import random
random.random()
```

???

On the other hand...

--

```console
$ bandit -r .
>> Issue: [B311:blacklist] Standard pseudo-random generators are not suitable
to use security/cryptographic purposes.
   Severity: Low   Confidence: High
   Location: ./main.py:9
   More Info: bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html
#b311-random
1       import random
2       random.random()
```

???

So unfortunately, there can be false positives which you may want to disable.

---

# How can we check security?

## Dependencies

???

Dependencies can be a bit of a minefield.

I generally suggest keeping dependencies up-to-date. Update them when you are adding a new one! Update them when you use them! Update them for no good reason!

--

With `safety` or `pipenv`:

```shell
$ pipenv check
Checking PEP 508 requirements…
Passed!
Checking installed package safety…
37261: django <2.2.3,>2.2 resolved (2.2.1 installed)!
[...] An HTTP request is not redirected to HTTPS [...]
```

???

**Safety** or pipenv check is a tool to check for known security vulnerabilities in your dependencies.

[DESCRIBE CONTRIVED EXAMPLE]

This is incredibly easy to use, with essentially no false positives.

You can even fail your continuous integration pipeline if there is one, forcing you to fix the security vulnerability.

--

With GitHub's `dependabot` creating Pull Requests:

![](../../2019-09-13-github-dependabot.png)

???

**Another alternative** is GitHub's `dependabot` which can create pull requests for you for out-of-date dependencies, and point out which of these are a security issue.

This is a little more user friendly as you can automatically run your CI pipeline on the pull request.

The only problem is, you can say no, or ignore it.

---

# What have we not covered?

* Code test coverage
  * "When a measure becomes a target, it ceases to be a good measure.""


* Some particular tools
  * e.g. `vulture`, the dead code finder


* Paid services


* Automating your own checks
  * e.g. Checking upgrade and downgrade database migrations
  * e.g. Checking new dependencies are pinned


* Linting non-Python parts of the codebase
  * e.g. `hadolint` to check Dockerfiles
  * e.g. `shellcheck` to check bash scripts


* All-in-one tools

???

I have not talked about code test coverage tools at all, because unless you intend to require strictly increasing test coverage, it is not useful day-to-day, at all, really, in any way, shape or form, ever. I wouldn't suggest doing this either, because, as Goodhart's law says... [SLIDE]

[SLIDE]

I have not really covered any paid tools or services like Codacy, Landscape.io, or SonarQube.

You can, of course, introduce your own automated checks. For example... [SLIDE]. I also miss out how you can write plugins, for example with flake8 and pylint.

I have also not covered non-Python parts of the codebase.
You might be surprised by the wealth of tools that are available.
For example, I found both of these tools to be invaluable... [SLIDE] In the past I've found both of these to produce fascinating output as I was not an expert in either of these areas.

I have not talked about more comprehensive all-in-one tools like Prospector for reasons including because they are more complex, making them harder to set up and properly integrate into everyone's workflows.

---

class: center, middle, inverse

# Workflow Integration

???

So, how can you do exactly that?

---

# How do you introduce new tools?

???

What are the different places that tools can slot into workflows?

--

## Within the Editor

???

**In my opinion** the best place for a tool is within your editor. Incorporating the tools directly where you are editing your code gives the fastest and most seamless experience, to the extent where you might not even realise that a linter was running.

I want to show two examples which demonstrate seamless integration.

--
* Automated fixing

  ```py
  random_choices = [
  "42", '...42?', 'I\'m not sure']
  ```

  ```py
  random_choices = ["42", "...42?", "I'm not sure"]
  ```

???

**The first** is where the editor or plugin to the editor can fix your code for you. Here, Sublime Text is configured with the sublack plugin to execute Black when you save, immediately reformatting your code, meaning you can see what everyone else will actually be reading.

It is harder, or currently not possible at all, to correctly, automatically fix errors from non-codestyle linters.

--

* Unobtrusive hinting

  ![](../../2019-09-13-pycharm-hinting.png)

???

**For those** kinds of warnings, then unobtrusive hinting is an excellent way to clearly bring the error to your attention without getting in the way of what you are immediately trying to do. It is the same as having a spellchecker when writing.

You do not have to go back and forth with tests, running tools, or going to and from continuous integration output.

Support across editors varies considerably, but the most common tools are usually supported either directly or with a plugin. The ability to pick up project-specific settings varies. [TALK editorconfig, talk IntelliJ eslint]

In addition, other people may or may not configure their editors, and they are under no obligation to actually fix any errors, so you cannot necessarily rely on this in collaborative projects.

---

# How do you introduce new tools?

## On Commit

???

The next best place is when you are committing code. I would also recommend this for collaborative projects.

--

```py
import random
import os
```

```shell
$ git commit -am "I am committing something useful"
```

![](../../2019-09-13-pre-commit.png)

???

[TALK OVER SLIDE]

However, there is a limit to how much you can put here because otherwise committing takes forever and you are getting in the way of someone's workflow.

For example, you might not want to add pylint because it is slow.

---

# How do you introduce new tools?

## During Pull Requests

???

The final place for these tools to run is the Continuous Integration pipeline when Pull Requests are created. This is where code review from other people takes place and ideally, by this point, most or all of the low-hanging fruit has been caught by automated tools that were run before the PR was created.

The most common method might be to separately view the errors on the failing build away from the Pull Request.

--

![](../../2019-09-13-pr-comment.png)

???

An improvement on this is where the CI tool can comment on the PR itself like a normal reviewer. There is need to hunt down errors and match them up with your code because you can immediately see the code.

---

# How do you introduce new tools (practically)?

???

Adding a new tool to a existing codebase can be difficult especially if it is a old, large project. Running a tool like pylint can output so many errors at first that you can be in deep despair.

There are three main methods.

--

* Let the tool fix everything
  * <https://engineering.depop.com/implementing-python-black-on-a-legacy-codebase-35b37f10ce18>

???

When using a tool like black that can actually edit your code, you can simply nuke your entire codebase in one go. Rather than go into the specific details on how to do this, I link to an article by a former colleague that did so on a large codebase, where he describes the challenges and solutions that they faced.

--


* Check only new code
  * Use `pre-commit`

???

The second technique is to check only new code, using a tool like pre-commit.

`git diff upstream/master "./**/*.py" | flake8 --diff --isolated`

--


* Divide and Conquer
  * Divide by file and directory
  * Divide by error type

???

The final trick is to divide and conquer, either by the files being checked, or by the types of errors you are checking for. To enable more and more checks to spread out the pain.

---

# Conclusion

My biased view, as the project gets larger:

1. Configure IDE

2. `.editorconfig`

3. `black` and `isort` (and maybe `docformatter`)

4. `pyflakes` (or `flake8`)

5. Use `pre-commit`

6. `safety` (and maybe `bandit`)

7. Other low handing fruit, e.g. `hadolint`

8. Use CI

9. `pylint`

???

Putting everything together, this is my biased conclusion on how I would automate code reviews.

Configure your IDE or text editor with linting tools to give you immediate-but-discreet feedback.

Use editorconfig, black and isort because they are so easy to set up.

Use pyflakes because it will not give you false positives.

Use pre-commit if you are working with other people.

Use safety and maybe bandit to start catching security issues.

Also look at non-Python files in your project.

Implement CI if you are working with other people that integrates with pull requests.

Finally, if you decide that you like pain, implement pylint.

That is how I would automate code review to save time and energy, taking care to save time and energy when doing the automation itself.

Thank you.


.footnote[A plethora of Python code review tools are available @ <https://github.com/PyCQA>]

---

class: center, middle, inverse

# Questions

???

Alternative / Additional Resources / References:

* https://realpython.com/python-code-quality/


